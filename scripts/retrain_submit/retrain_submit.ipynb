{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_config_search.data_transform_utils import fill_missing_values, assign_attr_types, add_NA_flags, one_hot_encode\n",
    "from data_config_search.data_transform_utils import add_logic_features, add_poly, add_spline, add_loading_features, add_group_features\n",
    "from data_config_search.data_transform_utils import scale, feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"sqlite:///../mlflow_data/mlflow.db\")\n",
    "# client.list_experiments()\n",
    "\n",
    "model_run = client.search_runs(\n",
    "    experiment_ids='3',\n",
    "    filter_string=\"metrics.auroc > 59.0 and parameters.run_id = 'b9a1484b322e48cf8fcbc070346b41db'\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.auroc DESC\"]\n",
    ")[0]\n",
    "\n",
    "# model_run = client.get_run('14bced548d8945148e94884cf7a5a220')\n",
    "data_run = client.get_run(model_run.data.params['run_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bool(x:str):\n",
    "    if x == 'False': return False\n",
    "    elif x == 'True': return True\n",
    "    else: raise ValueError('Only \"True\" and \"False\" allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data parameters\n",
    "seeds = [int(x) for x in data_run.data.params['seed'][1:-1].replace(',', '').split()]\n",
    "imputer_params = {'method': data_run.data.params['imputer_method'], 'by_product_code': data_run.data.params['imputer_by_prod_code']}\n",
    "attr2_type = data_run.data.params['attr2_type']\n",
    "attr3_type = data_run.data.params['attr3_type']\n",
    "group_dict = {'use': str_to_bool(data_run.data.params['group_features_used'])}\n",
    "poly_dict = {'use': str_to_bool(data_run.data.params['poly_features_used']), 'degree': int(data_run.data.params['poly_degree'])}\n",
    "spline_dict = {'use': str_to_bool(data_run.data.params['spline_params_used']), 'n_knots': int(data_run.data.params['spline_n_knots']), 'degree': int(data_run.data.params['spline_degree'])}\n",
    "logic_dict = {'use': str_to_bool(data_run.data.params['logic_features_used'])}\n",
    "loading_dict = {'use': str_to_bool(data_run.data.params['loading_features_used'])}\n",
    "scaling_dict = {'use': str_to_bool(data_run.data.params['scaling_used']), 'method': data_run.data.params['scaling_method']}\n",
    "fselection_steps = {'Constant_Features': {'frac_constant_values': 0.99}}\n",
    "stepwise = str_to_bool(data_run.data.params['fs_stepwise_used'])\n",
    "n_features_found = data_run.data.params['n_features_used']\n",
    "\n",
    "# Read model parameters\n",
    "C = float(model_run.data.params['C'])\n",
    "max_iter = int(model_run.data.params['max_iter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test = pd.read_csv('../data/test.csv', index_col='id')\n",
    "len_train = len(train)\n",
    "\n",
    "data = pd.concat([train.drop(columns=['failure']), test], axis=0)\n",
    "\n",
    "data = (data\n",
    "    .pipe(add_NA_flags, cols=['measurement_3', 'measurement_5'])\n",
    "    .pipe(fill_missing_values, params=imputer_params, extra_params={'seed':seeds[0], 'n_knn':3})\n",
    "    .pipe(assign_attr_types, attr_types={'attribute_2':attr2_type, 'attribute_3':attr3_type})\n",
    "    .pipe(add_group_features, group_dict=group_dict)\n",
    "    .pipe(one_hot_encode)\n",
    "    .pipe(add_poly, poly_dict=poly_dict)\n",
    "    .pipe(add_spline, spline_dict=spline_dict)\n",
    "    .pipe(add_logic_features, logic_dict=logic_dict)\n",
    "    .pipe(add_loading_features, loading_dict=loading_dict)\n",
    "    .pipe(scale, scale_dict=scaling_dict)\n",
    "    .pipe(feature_selection, y=train['failure'], steps=fselection_steps, stepwise=stepwise, seed=seeds[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N features from data_config_search: 10\n",
      "N features from rerun: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'N features from data_config_search: {n_features_found}')\n",
    "print(f'N features from rerun: {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train test split and check if all ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E']\n",
      "['F' 'G' 'H' 'I']\n"
     ]
    }
   ],
   "source": [
    "train_ = pd.concat([data[:len_train], train['failure']], axis=1)\n",
    "test_ = data[len_train:]\n",
    "\n",
    "print(train.product_code.unique())\n",
    "print(test.product_code.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_.drop(columns=['product_code', 'failure'])\n",
    "X_test = test_.drop(columns=['product_code'])\n",
    "y_train = train_['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error :0.5936324926123512\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=max_iter, C=C)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Train error\n",
    "y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "print(f'Train error :{roc_auc_score(y_train, y_pred_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(zip(list(X_test.index), y_pred), columns=['id', 'failure'])\n",
    "pred_df.to_csv('../submissions/submission_SPLINE.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d45a8b0143f640e47078c8e28a07a95d5ab34938eb974c51e60e227b64f716a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
