{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_config_search.data_transform_utils import fill_missing_values, assign_attr_types, add_NA_flags, one_hot_encode\n",
    "from data_config_search.data_transform_utils import add_logic_features, add_poly, add_spline, add_loading_features, add_group_features\n",
    "from data_config_search.data_transform_utils import scale, feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"sqlite:///../../mlflow_data/mlflow.db\")\n",
    "# client.list_experiments()\n",
    "\n",
    "run = client.search_runs(\n",
    "    experiment_ids='2',\n",
    "    filter_string=\"metrics.auroc > 59.0\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.auroc DESC\"]\n",
    ")[0]\n",
    "\n",
    "# Or\n",
    "run = client.get_run('b9a1484b322e48cf8fcbc070346b41db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bool(x:str):\n",
    "    if x == 'False': return False\n",
    "    elif x == 'True': return True\n",
    "    else: raise ValueError('Only \"True\" and \"False\" allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all parameters\n",
    "seeds = [int(x) for x in run.data.params['seed'][1:-1].replace(',', '').split()]\n",
    "imputer_params = {'method': run.data.params['imputer_method'], 'by_product_code': run.data.params['imputer_by_prod_code']}\n",
    "attr2_type = run.data.params['attr2_type']\n",
    "attr3_type = run.data.params['attr3_type']\n",
    "group_dict = {'use': str_to_bool(run.data.params['group_features_used'])}\n",
    "poly_dict = {'use': str_to_bool(run.data.params['poly_features_used']), 'degree': int(run.data.params['poly_degree'])}\n",
    "spline_dict = {'use': str_to_bool(run.data.params['spline_params_used']), 'n_knots': int(run.data.params['spline_n_knots']), 'degree': int(run.data.params['spline_degree'])}\n",
    "logic_dict = {'use': str_to_bool(run.data.params['logic_features_used'])}\n",
    "loading_dict = {'use': str_to_bool(run.data.params['loading_features_used'])}\n",
    "scaling_dict = {'use': str_to_bool(run.data.params['scaling_used']), 'method': run.data.params['scaling_method']}\n",
    "fselection_steps = {'Constant_Features': {'frac_constant_values': 0.99}}\n",
    "stepwise = str_to_bool(run.data.params['fs_stepwise_used'])\n",
    "n_features_found = run.data.params['n_features_used']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate dataset from run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train.csv', index_col='id')\n",
    "data = train.drop(columns=['failure'])\n",
    "\n",
    "data = (data\n",
    "    .pipe(add_NA_flags, cols=['measurement_3', 'measurement_5'])\n",
    "    .pipe(fill_missing_values, params=imputer_params, extra_params={'seed':seeds[0], 'n_knn':3})\n",
    "    .pipe(assign_attr_types, attr_types={'attribute_2':attr2_type, 'attribute_3':attr3_type})\n",
    "    .pipe(add_group_features, group_dict=group_dict)\n",
    "    .pipe(one_hot_encode)\n",
    "    .pipe(add_poly, poly_dict=poly_dict)\n",
    "    .pipe(add_spline, spline_dict=spline_dict)\n",
    "    .pipe(add_logic_features, logic_dict=logic_dict)\n",
    "    .pipe(add_loading_features, loading_dict=loading_dict)\n",
    "    .pipe(scale, scale_dict=scaling_dict)\n",
    "    .pipe(feature_selection, y=train['failure'], steps=fselection_steps, stepwise=stepwise, seed=seeds[0])\n",
    "    )\n",
    "\n",
    "print(f'N features from data_config_search: {n_features_found}')\n",
    "print(f'N features from rerun: {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline model as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.72083259424164\n",
      "AUROC: 59.27206188927491\n",
      "AUROC dict: {'auroc_fold_A': 59.478778768544394, 'auroc_fold_B': 59.42314555002655, 'auroc_fold_C': 58.79238579595665, 'auroc_fold_D': 60.05598021582733, 'auroc_fold_E': 58.61001911601959}\n"
     ]
    }
   ],
   "source": [
    "model_seeds = [4,66,128]\n",
    "auroc_dict = {'auroc_fold_A': 0, 'auroc_fold_B': 0, 'auroc_fold_C': 0, 'auroc_fold_D': 0, 'auroc_fold_E': 0}\n",
    "accuracy_list = []\n",
    "\n",
    "for model_seed in model_seeds:\n",
    "\n",
    "    # Use 5-fold split\n",
    "    kfold = GroupKFold(n_splits=5)\n",
    "    X = data\n",
    "    y = train['failure']\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y, train['product_code'])):\n",
    "            \n",
    "        X_train = X.loc[train_idx]\n",
    "        X_val = X.loc[val_idx]\n",
    "        y_train = y.loc[train_idx]\n",
    "        y_val = y.loc[val_idx]\n",
    "\n",
    "        val_prod_code = X_val['product_code'].unique()[0]\n",
    "        X_train = X_train.drop(columns=['product_code'])\n",
    "        X_val = X_val.drop(columns=['product_code'])\n",
    "\n",
    "        # model_ = model_dict[model]\n",
    "        model_ = LogisticRegression(random_state=model_seed, max_iter=200)\n",
    "        model_.fit(X_train, y_train)\n",
    "        y_pred = model_.predict_proba(X_val)[:,1]\n",
    "\n",
    "        auroc_dict[f'auroc_fold_{val_prod_code}'] += roc_auc_score(y_val, y_pred)\n",
    "        accuracy_list.append(np.mean((y_pred >= 0.5).astype('int') == y_val))\n",
    "\n",
    "auroc_dict = {k:v/len(model_seeds) for k,v in auroc_dict.items()}\n",
    "acc_ = np.mean(accuracy_list)*100\n",
    "auroc_ = np.mean(list(auroc_dict.values()))*100\n",
    "auroc_dict_ = {k:v*100 for k,v in auroc_dict.items()}\n",
    "\n",
    "print(f'Accuracy: {acc_}')\n",
    "print(f'AUROC: {auroc_}')\n",
    "print(f'AUROC dict: {auroc_dict_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/3', experiment_id='3', lifecycle_stage='active', name='Kaggle-TPSAUG2022-model-config', tags={}>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///../../mlflow_data/mlflow.db\")\n",
    "mlflow.set_experiment(\"Kaggle-TPSAUG2022-model-config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    auroc_dict = {'auroc_fold_A': 0, 'auroc_fold_B': 0, 'auroc_fold_C': 0, 'auroc_fold_D': 0, 'auroc_fold_E': 0}\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for model_seed in model_seeds:\n",
    "\n",
    "            # Use 5-fold split\n",
    "            kfold = GroupKFold(n_splits=5)\n",
    "            X = data\n",
    "            y = train['failure']\n",
    "            for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y, train['product_code'])):\n",
    "                    \n",
    "                X_train = X.loc[train_idx]\n",
    "                X_val = X.loc[val_idx]\n",
    "                y_train = y.loc[train_idx]\n",
    "                y_val = y.loc[val_idx]\n",
    "\n",
    "                val_prod_code = X_val['product_code'].unique()[0]\n",
    "                X_train = X_train.drop(columns=['product_code'])\n",
    "                X_val = X_val.drop(columns=['product_code'])\n",
    "\n",
    "                # model_ = model_dict[model]\n",
    "                model_ = LogisticRegression(**params, random_state=model_seed)\n",
    "                model_.fit(X_train, y_train)\n",
    "                y_pred = model_.predict_proba(X_val)[:,1]\n",
    "\n",
    "                auroc_dict[f'auroc_fold_{val_prod_code}'] += roc_auc_score(y_val, y_pred)\n",
    "\n",
    "        auroc_dict = {k:v/len(model_seeds) for k,v in auroc_dict.items()}\n",
    "        auroc_ = np.mean(list(auroc_dict.values()))*100\n",
    "        auroc_dict_ = {k:v*100 for k,v in auroc_dict.items()}\n",
    "\n",
    "        mlflow.set_tag('iteration', '5')\n",
    "        mlflow.log_param('run_id', run.info.run_id)\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('auroc', auroc_)\n",
    "        mlflow.log_metrics(auroc_dict_)\n",
    "\n",
    "    return {'loss': -auroc_, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:05<00:00,  3.07trial/s, best loss: -59.27941022249696]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_iter': scope.int(hp.quniform('max_iter', 200, 500, 1)),\n",
    "    'C': hp.quniform('C', 0.01, 2, 0.01)\n",
    "    # 'l1_ratio': hp.quniform('l1_ratio', 0, 1, 1),\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=200,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.02, 'max_iter': 427.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d45a8b0143f640e47078c8e28a07a95d5ab34938eb974c51e60e227b64f716a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
